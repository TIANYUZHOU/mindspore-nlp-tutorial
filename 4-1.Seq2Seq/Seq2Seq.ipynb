{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "metropolitan-married",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore\n",
    "import numpy as np\n",
    "import mindspore.nn as nn\n",
    "from mindspore import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "internal-covering",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch(seq_data, num_dic, n_step):\n",
    "    input_batch, output_batch, target_batch = [], [], []\n",
    "\n",
    "    for seq in seq_data:\n",
    "        for i in range(2):\n",
    "            seq[i] = seq[i] + 'P' * (n_step - len(seq[i]))\n",
    "\n",
    "        input = [num_dic[n] for n in seq[0]]\n",
    "        output = [num_dic[n] for n in ('S' + seq[1])]\n",
    "        target = [num_dic[n] for n in (seq[1] + 'E')]\n",
    "\n",
    "        input_batch.append(np.eye(n_class)[input])\n",
    "        output_batch.append(np.eye(n_class)[output])\n",
    "        target_batch.append(target) # not one-hot\n",
    "\n",
    "    # make tensor\n",
    "    return Tensor(input_batch, mindspore.float32), Tensor(output_batch, mindspore.float32), Tensor(target_batch, mindspore.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "compressed-resort",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class Seq2Seq(nn.Cell):\n",
    "    def __init__(self, n_class, n_hidden, dropout):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "\n",
    "        self.enc_cell = nn.RNN(input_size=n_class, hidden_size=n_hidden, dropout=dropout)\n",
    "        self.dec_cell = nn.RNN(input_size=n_class, hidden_size=n_hidden, dropout=dropout)\n",
    "        self.fc = nn.Dense(n_hidden, n_class)\n",
    "        \n",
    "        \n",
    "    def construct(self, enc_input, enc_hidden, dec_input):\n",
    "        enc_input = enc_input.transpose((1, 0, 2)) # enc_input: [max_len(=n_step, time step), batch_size, n_class]\n",
    "        dec_input = dec_input.transpose((1, 0, 2)) # dec_input: [max_len(=n_step, time step), batch_size, n_class]\n",
    "\n",
    "        # enc_states : [num_layers(=1) * num_directions(=1), batch_size, n_hidden]\n",
    "        _, enc_states = self.enc_cell(enc_input, enc_hidden)\n",
    "        # outputs : [max_len+1(=6), batch_size, num_directions(=1) * n_hidden(=128)]\n",
    "        outputs, _ = self.dec_cell(dec_input, enc_states)\n",
    "\n",
    "        model = self.fc(outputs) # model : [max_len+1(=6), batch_size, n_class]\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8581eac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WithLossCell(nn.Cell):\n",
    "    def __init__(self, backbone, loss_fn):\n",
    "        super(WithLossCell, self).__init__(auto_prefix=False)\n",
    "        self._backbone = backbone\n",
    "        self._loss_fn = loss_fn\n",
    "\n",
    "    def construct(self, *args):\n",
    "        out = self._backbone(*args[:-1])\n",
    "        out = out.transpose((1, 0, 2))\n",
    "        return self._loss_fn(out.view(-1, out.shape[-1]), args[-1].view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "impaired-treat",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_step = 5\n",
    "n_hidden = 128\n",
    "dropout = 0.5\n",
    "char_arr = [c for c in 'SEPabcdefghijklmnopqrstuvwxyz']\n",
    "num_dic = {n: i for i, n in enumerate(char_arr)}\n",
    "seq_data = [['man', 'women'], ['black', 'white'], ['king', 'queen'], ['girl', 'boy'], ['up', 'down'], ['high', 'low']]\n",
    "\n",
    "n_class = len(num_dic)\n",
    "batch_size = len(seq_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "structured-external",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(21003:4594382336,MainProcess):2022-01-23-20:15:19.219.407 [mindspore/nn/layer/rnns.py:387] dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "[WARNING] ME(21003:4594382336,MainProcess):2022-01-23-20:15:19.226.556 [mindspore/nn/layer/rnns.py:387] dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n"
     ]
    }
   ],
   "source": [
    "model = Seq2Seq(n_class, n_hidden, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "japanese-platform",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\n",
    "optimizer = nn.Adam(model.get_parameters(), learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "governmental-narrative",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_batch, output_batch, target_batch = make_batch(seq_data, num_dic, n_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "parallel-medicare",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore import context\n",
    "context.set_context(mode=context.GRAPH_MODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "celtic-variety",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "[WARNING] DEBUG(21003,0x111d8b600,python):2022-01-23-20:15:19.359.803 [mindspore/ccsrc/debug/debugger/debugger.cc:95] Debugger] Not enabling debugger. Debugger does not support CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1000 cost = 0.001025\n",
      "Epoch: 2000 cost = 0.000275\n",
      "Epoch: 3000 cost = 0.000117\n",
      "Epoch: 4000 cost = 0.000058\n",
      "Epoch: 5000 cost = 0.000031\n"
     ]
    }
   ],
   "source": [
    "net_with_criterion = WithLossCell(model, criterion)\n",
    "train_network = nn.TrainOneStepCell(net_with_criterion, optimizer)\n",
    "\n",
    "for epoch in range(5000):\n",
    "    # make hidden shape [num_layers * num_directions, batch_size, n_hidden]\n",
    "    hidden = Tensor(np.zeros((1, batch_size, n_hidden)), mindspore.float32)\n",
    "    # input_batch : [batch_size, max_len(=n_step, time step), n_class]\n",
    "    # output_batch : [batch_size, max_len+1(=n_step, time step) (becase of 'S' or 'E'), n_class]\n",
    "    # target_batch : [batch_size, max_len+1(=n_step, time step)], not one-hot\n",
    "    loss = train_network(input_batch, hidden, output_batch, target_batch)\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss.asnumpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "resident-debate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "man -> women\n",
      "mans -> women\n",
      "king -> queen\n",
      "black -> white\n",
      "upp -> down\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "def translate(word):\n",
    "    input_batch, output_batch, _ = make_batch([[word, 'P' * len(word)]],  num_dic, n_step)\n",
    "    # make hidden shape [num_layers * num_directions, batch_size, n_hidden]\n",
    "    hidden = Tensor(np.zeros((1, 1, n_hidden)), mindspore.float32)\n",
    "    output = model(input_batch, hidden, output_batch)\n",
    "    # output : [max_len+1(=6), batch_size(=1), n_class]\n",
    "\n",
    "    predict = output.asnumpy().argmax(2) # select n_class dimension\n",
    "    decoded = [char_arr[i[0]] for i in predict]\n",
    "    end = decoded.index('E')\n",
    "    translated = ''.join(decoded[:end])\n",
    "\n",
    "    return translated.replace('P', '')\n",
    "\n",
    "print('test')\n",
    "print('man ->', translate('man'))\n",
    "print('mans ->', translate('mans'))\n",
    "print('king ->', translate('king'))\n",
    "print('black ->', translate('black'))\n",
    "print('upp ->', translate('upp'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
